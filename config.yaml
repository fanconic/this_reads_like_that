name: "test_protogpt2_2"
random_state: 42
wandb_logging: True

data:
    dataset: "reviews"
    val_size: 0.2
    data_name: "rt-polarity"
    data_dir: "./src/data"

train:
    batch_size: 128
    epochs: 10
    verbose: False

model:
    name: "proto"
    submodel: "gpt2"
    embed_dim: 768
    n_classes: 2
    freeze_layers: True
    n_prototypes: 20
    similaritymeasure: "L2"
    proto_size: 1
    attention: False
    dilated: [1]


#    name: "bert"
#    embed_dim: 128
#    n_classes: 4

optimizer:
    name: "adam"
    lr: 0.001
    momentum: 0.9
    weight_decay: 0.0005
    betas: [0.9, 0.999]
    T_0: 10

scheduler:
    name: "poly"
    lr_reduce_factor: 0.1
    patience_lr_reduce: 10
    poly_reduce: 0.9

loss:
    lambda1: 0.2
    lambda2: 0.2
    lambda3: 0.1
    lambda4: 0.3
    lambda5: 0.001

